{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# introduction to the vectorizing principle\n",
    "\n",
    "## part 7: aggregation functions\n",
    "\n",
    "The core of the vectorizing principle is treating rows separately. In this part, we look on \n",
    "aggregation functions which group the data and perform vectorized operations on each group.\n",
    "\n",
    "#### the following code shows an aggregation function call in different libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T17:00:52.280290760Z",
     "start_time": "2023-08-16T17:00:51.622050052Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import sqlalchemy as sa\n",
    "import ibis\n",
    "from ibis import _ as col\n",
    "import pydiverse.transform as pdt\n",
    "from pydiverse.pipedag import Flow, Stage, Table, materialize\n",
    "from pydiverse.transform import λ\n",
    "from pydiverse.transform.core.verbs import (\n",
    "    mutate, alias, group_by, summarise, arrange, build_query,\n",
    ")\n",
    "from pydiverse.transform.eager import PandasTableImpl\n",
    "from pydiverse.transform.lazy import SQLTableImpl\n",
    "\n",
    "\n",
    "@materialize(input_type=pd.DataFrame, version=\"1.0.0\")\n",
    "def task_pandas(titanic: pd.DataFrame):\n",
    "    return (\n",
    "        titanic\n",
    "        .assign(age_bucket=(titanic.age + 4.999).round(-1))\n",
    "        .groupby(\"age_bucket\")\n",
    "        .agg(samples=(\"age_bucket\", \"count\"), survival_likelyhood=(\"survived\", \"mean\"))\n",
    "        .sort_values(\"age_bucket\")\n",
    "    )\n",
    "\n",
    "\n",
    "@materialize(input_type=pl.DataFrame, version=\"1.0.0\")\n",
    "def task_polars(titanic: pl.DataFrame):\n",
    "    return (\n",
    "        titanic\n",
    "        .with_columns(age_bucket=(((pl.col(\"age\") + 4.999) / 10).round() * 10))\n",
    "        .groupby(\"age_bucket\")\n",
    "        .agg(samples=pl.col(\"age_bucket\").count(),\n",
    "             survival_likelyhood=pl.col(\"survived\").mean())\n",
    "        .sort(\"age_bucket\")\n",
    "    )\n",
    "\n",
    "\n",
    "@materialize(input_type=PandasTableImpl, version=\"1.0.0\")\n",
    "def task_transform_df(titanic: pdt.Table):\n",
    "    return (\n",
    "        titanic\n",
    "        >> mutate(age_bucket = round(λ.age + 4.999, -1))\n",
    "        >> group_by(λ.age_bucket)\n",
    "        >> summarise(samples=λ.age_bucket.count(),\n",
    "                    survival_likelyhood=λ.survived.mean())\n",
    "        >> arrange(λ.age_bucket)\n",
    "        >> alias(\"transform_df\")\n",
    "    )\n",
    "\n",
    "\n",
    "@materialize(input_type=SQLTableImpl, lazy=True)\n",
    "def task_transform_sql(titanic: pdt.Table):\n",
    "    return (\n",
    "        titanic\n",
    "        >> mutate(age_bucket = round(λ.age + 4.999, -1))\n",
    "        >> group_by(λ.age_bucket)\n",
    "        >> summarise(samples=λ.age_bucket.count(),\n",
    "                    survival_likelyhood=λ.survived.mean())\n",
    "        >> arrange(λ.age_bucket)\n",
    "        >> alias(\"transform_sql\")\n",
    "    )\n",
    "\n",
    "\n",
    "@materialize(input_type=ibis.api.Table, lazy=True)\n",
    "def task_ibis(titanic: ibis.api.Table):\n",
    "    return (\n",
    "        titanic\n",
    "        .mutate(age_bucket = (col.age + ibis.literal(4.999, \"decimal\")).round(-1))\n",
    "        .group_by(col.age_bucket)\n",
    "        .aggregate(samples=col.age_bucket.count(), survival_likelyhood=col.survived.mean())\n",
    "        .order_by(col.age_bucket)\n",
    "    )\n",
    "\n",
    "\n",
    "@materialize(input_type=sa.Table, lazy=True)\n",
    "def task_sqlalchemy(titanic: sa.Table):\n",
    "    age_bucket = sa.func.round(titanic.c.age + 4.999, -1).label(\"age_bucket\")\n",
    "    return sa.select(\n",
    "        age_bucket,\n",
    "        sa.func.count(age_bucket).label(\"samples\"),\n",
    "        sa.func.avg(titanic.c.survived).label(\"survival_likelyhood\")\n",
    "    ).select_from(titanic).group_by(age_bucket).order_by(age_bucket)\n",
    "\n",
    "\n",
    "@materialize(input_type=sa.Table, lazy=True)\n",
    "def task_sql(titanic: sa.Table):\n",
    "    return sa.text(f\"\"\"\n",
    "        SELECT round((titanic.age + 4.999) / CAST(10 AS NUMERIC)) * 10        AS age_bucket,\n",
    "               count(round((titanic.age + 4.999) / CAST(10 AS NUMERIC)) * 10) AS samples,\n",
    "               AVG(titanic.survived)                                          AS survival_likelyhood\n",
    "        FROM {titanic.original.schema}.{titanic.name} AS titanic\n",
    "        GROUP BY round((titanic.age + 4.999) / CAST(10 AS NUMERIC)) * 10\n",
    "        ORDER BY round((titanic.age + 4.999) / CAST(10 AS NUMERIC)) * 10 ASC NULLS LAST\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### define remaining tasks and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T17:00:52.284740825Z",
     "start_time": "2023-08-16T17:00:52.282636348Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@materialize(version=\"1.0.0\")\n",
    "def read_input_data():\n",
    "    titanic = pd.read_csv(\n",
    "        'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "    )\n",
    "    return Table(titanic, name=\"titanic\")\n",
    "\n",
    "\n",
    "@materialize(input_type=pd.DataFrame, version=\"1.0.0\")\n",
    "def print_tables(tbls: list[pd.DataFrame]):\n",
    "    for tbl in tbls:\n",
    "        print(f\"\\n\\n{tbl}\")\n",
    "\n",
    "\n",
    "def get_pipeline():\n",
    "    tasks = [task_pandas, task_polars, task_transform_df, task_transform_sql,\n",
    "             task_ibis, task_sqlalchemy, task_sql]\n",
    "    with Flow(\"flow\") as flow:\n",
    "        with Stage(\"t1_raw_input\"):\n",
    "            titanic = read_input_data()\n",
    "\n",
    "        with Stage(\"t2_transformed_data\"):\n",
    "            out_tbls = [task(titanic) for task in tasks]\n",
    "            print_tables(out_tbls)\n",
    "\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### define pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T17:00:52.328338448Z",
     "start_time": "2023-08-16T17:00:52.285573682Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_pipeline():\n",
    "    tasks = [task_pandas, task_polars, task_transform_df, task_transform_sql,\n",
    "             task_ibis, task_sqlalchemy, task_sql]\n",
    "    with Flow(\"flow\") as flow:\n",
    "        with Stage(\"t1_raw_input\"):\n",
    "            titanic = read_input_data()\n",
    "\n",
    "        with Stage(\"t2_transformed_data\"):\n",
    "            out_tbls = [task(titanic) for task in tasks]\n",
    "            print_tables(out_tbls)\n",
    "\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### setup logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T17:00:52.328568407Z",
     "start_time": "2023-08-16T17:00:52.328220790Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pydiverse.pipedag.util.structlog import setup_logging\n",
    "setup_logging(log_level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### run pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T17:00:53.444536904Z",
     "start_time": "2023-08-16T17:00:52.328441425Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-08-06 09:27:24.933038\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitialized SQL Table Store   \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m \u001b[36mengine_url\u001b[0m=\u001b[35mduckdb:////tmp/pipedag/vectorization/db.duckdb\u001b[0m \u001b[36mschema_prefix\u001b[0m=\u001b[35m\u001b[0m \u001b[36mschema_suffix\u001b[0m=\u001b[35m\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.939821\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mInitialized SQL Table Store   \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m \u001b[36mengine_url\u001b[0m=\u001b[35mduckdb:////tmp/pipedag/vectorization/db.duckdb\u001b[0m \u001b[36mschema_prefix\u001b[0m=\u001b[35m\u001b[0m \u001b[36mschema_suffix\u001b[0m=\u001b[35m\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.940331\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting IPCServer            \u001b[0m [\u001b[0m\u001b[1m\u001b[34mRunContextServer\u001b[0m]\u001b[0m \u001b[36maddress\u001b[0m=\u001b[35mtcp://127.0.0.1:64845\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.955160\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE SCHEMA IF NOT EXISTS pipedag_metadata\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.959829\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE SCHEMA IF NOT EXISTS t1_raw_input\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.960592\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mDROP SCHEMA IF EXISTS t1_raw_input__even CASCADE\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.961364\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE SCHEMA t1_raw_input__even\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.977845\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE VIEW t1_raw_input__even.titanic AS\n",
      "    \u001b[35mSELECT * \n",
      "    \u001b[35mFROM t1_raw_input.titanic\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.982003\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFound task in cache. Using cached result.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'read_input_data'\u001b[0m]\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'read_input_data' 0x16c7c3390 (id: 0)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.982629\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask finished successfully    \u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'read_input_data'\u001b[0m]\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35m<FinalTaskState.CACHE_VALID: 2>\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'read_input_data' 0x16c7c3390 (id: 0)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.983153\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCommitting stage              \u001b[0m [\u001b[0m\u001b[1m\u001b[34mCommit Stage\u001b[0m]\u001b[0m \u001b[36mstage\u001b[0m=\u001b[35m<Stage: t1_raw_input>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.984300\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStage is cache valid          \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m \u001b[36mstage\u001b[0m=\u001b[35m<Stage: t1_raw_input>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.988106\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask finished successfully    \u001b[0m [\u001b[0m\u001b[1m\u001b[34mCommit Stage\u001b[0m]\u001b[0m \u001b[36mstage\u001b[0m=\u001b[35m<Stage: t1_raw_input>\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35m<FinalTaskState.COMPLETED: 1>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.990626\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE SCHEMA IF NOT EXISTS t2_transformed_data\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.991304\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mDROP SCHEMA IF EXISTS t2_transformed_data__odd CASCADE\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:24.992319\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE SCHEMA t2_transformed_data__odd\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.000867\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE VIEW t2_transformed_data__odd.task_pandas_j63nc4stdmsqfsxeg3r4_0000 AS\n",
      "    \u001b[35mSELECT * \n",
      "    \u001b[35mFROM t2_transformed_data.task_pandas_j63nc4stdmsqfsxeg3r4_0000\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.004277\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFound task in cache. Using cached result.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'task_pandas'\u001b[0m]\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'task_pandas' 0x107cd1d90 (id: 2)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.004872\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask finished successfully    \u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'task_pandas'\u001b[0m]\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35m<FinalTaskState.CACHE_VALID: 2>\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'task_pandas' 0x107cd1d90 (id: 2)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.011440\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE VIEW t2_transformed_data__odd.task_polars_d42ck7w3oge7b2vp44x6_0000 AS\n",
      "    \u001b[35mSELECT * \n",
      "    \u001b[35mFROM t2_transformed_data.task_polars_d42ck7w3oge7b2vp44x6_0000\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.014712\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFound task in cache. Using cached result.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'task_polars'\u001b[0m]\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'task_polars' 0x107cdab50 (id: 3)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.015319\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask finished successfully    \u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'task_polars'\u001b[0m]\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35m<FinalTaskState.CACHE_VALID: 2>\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'task_polars' 0x107cdab50 (id: 3)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.021806\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE VIEW t2_transformed_data__odd.transform_df AS\n",
      "    \u001b[35mSELECT * \n",
      "    \u001b[35mFROM t2_transformed_data.transform_df\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.026839\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFound task in cache. Using cached result.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'task_transform_df'\u001b[0m]\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'task_transform_df' 0x16c651d10 (id: 4)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.027947\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask finished successfully    \u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'task_transform_df'\u001b[0m]\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35m<FinalTaskState.CACHE_VALID: 2>\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'task_transform_df' 0x16c651d10 (id: 4)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.030384\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFailed to retrieve table from local table cache\u001b[0m [\u001b[0m\u001b[1m\u001b[34mParquetTableCache\u001b[0m]\u001b[0m \u001b[36mcause\u001b[0m=\u001b[35mCan't retrieve Table as type <class 'pydiverse.transform.lazy.sql_table.sql_table.SQLTableImpl'>. This is either because no TableHook has been registered for this type, or because not all requirements have been met for the corresponding hook.\n",
      "Hooks with unmet requirements: pydiverse.pipedag.backend.table.sql.hooks.TidyPolarsTableHook\u001b[0m \u001b[36mtable\u001b[0m=\u001b[35m<Table 'titanic' (t1_raw_input)>\u001b[0m\n",
      "/Users/martin/micromamba/envs/vectorization/lib/python3.11/site-packages/duckdb_engine/__init__.py:173: DuckDBEngineWarning: duckdb-engine doesn't yet support reflection on indices\n",
      "  warnings.warn(\n",
      "\u001b[2m2024-08-06 09:27:25.172931\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE VIEW t2_transformed_data__odd.transform_sql AS\n",
      "    \u001b[35mSELECT * \n",
      "    \u001b[35mFROM t2_transformed_data.transform_sql\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.175180\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLazy cache of table 'transform_sql' found\u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.178566\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask finished successfully    \u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'task_transform_sql'\u001b[0m]\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35m<FinalTaskState.CACHE_VALID: 2>\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'task_transform_sql' 0x16c7c3510 (id: 5)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.180363\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFailed to retrieve table from local table cache\u001b[0m [\u001b[0m\u001b[1m\u001b[34mParquetTableCache\u001b[0m]\u001b[0m \u001b[36mcause\u001b[0m=\u001b[35mCan't retrieve Table as type <class 'ibis.expr.types.relations.Table'>. This is either because no TableHook has been registered for this type, or because not all requirements have been met for the corresponding hook.\n",
      "Hooks with unmet requirements: pydiverse.pipedag.backend.table.sql.hooks.TidyPolarsTableHook\u001b[0m \u001b[36mtable\u001b[0m=\u001b[35m<Table 'titanic' (t1_raw_input)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.216047\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE VIEW t2_transformed_data__odd.task_ibis_vz4vcva2ozcxtyt3i37p_0000 AS\n",
      "    \u001b[35mSELECT * \n",
      "    \u001b[35mFROM t2_transformed_data.task_ibis_vz4vcva2ozcxtyt3i37p_0000\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.217992\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLazy cache of table 'task_ibis_vz4vcva2ozcxtyt3i37p_0000' found\u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.221057\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask finished successfully    \u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'task_ibis'\u001b[0m]\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35m<FinalTaskState.CACHE_VALID: 2>\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'task_ibis' 0x16c7c3d10 (id: 6)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.222745\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFailed to retrieve table from local table cache\u001b[0m [\u001b[0m\u001b[1m\u001b[34mParquetTableCache\u001b[0m]\u001b[0m \u001b[36mcause\u001b[0m=\u001b[35mCan't retrieve Table as type <class 'sqlalchemy.sql.schema.Table'>. This is either because no TableHook has been registered for this type, or because not all requirements have been met for the corresponding hook.\n",
      "Hooks with unmet requirements: pydiverse.pipedag.backend.table.sql.hooks.TidyPolarsTableHook\u001b[0m \u001b[36mtable\u001b[0m=\u001b[35m<Table 'titanic' (t1_raw_input)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.347942\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE VIEW t2_transformed_data__odd.task_sqlalchemy_w4wadategregxdnowbbn_0000 AS\n",
      "    \u001b[35mSELECT * \n",
      "    \u001b[35mFROM t2_transformed_data.task_sqlalchemy_w4wadategregxdnowbbn_0000\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.349734\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLazy cache of table 'task_sqlalchemy_w4wadategregxdnowbbn_0000' found\u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.352412\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask finished successfully    \u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'task_sqlalchemy'\u001b[0m]\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35m<FinalTaskState.CACHE_VALID: 2>\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'task_sqlalchemy' 0x16c7cc390 (id: 7)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.353762\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFailed to retrieve table from local table cache\u001b[0m [\u001b[0m\u001b[1m\u001b[34mParquetTableCache\u001b[0m]\u001b[0m \u001b[36mcause\u001b[0m=\u001b[35mCan't retrieve Table as type <class 'sqlalchemy.sql.schema.Table'>. This is either because no TableHook has been registered for this type, or because not all requirements have been met for the corresponding hook.\n",
      "Hooks with unmet requirements: pydiverse.pipedag.backend.table.sql.hooks.TidyPolarsTableHook\u001b[0m \u001b[36mtable\u001b[0m=\u001b[35m<Table 'titanic' (t1_raw_input)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.480051\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExecuting sql                 \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "    [\u001b[36mquery\u001b[0m]\n",
      "    \u001b[35mCREATE VIEW t2_transformed_data__odd.task_sql_j3362cymhyyu3gjkc2l6_0000 AS\n",
      "    \u001b[35mSELECT * \n",
      "    \u001b[35mFROM t2_transformed_data.task_sql_j3362cymhyyu3gjkc2l6_0000\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.482393\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLazy cache of table 'task_sql_j3362cymhyyu3gjkc2l6_0000' found\u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.485254\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask finished successfully    \u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'task_sql'\u001b[0m]\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35m<FinalTaskState.CACHE_VALID: 2>\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'task_sql' 0x16c7cc3d0 (id: 8)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.489371\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFound task in cache. Using cached result.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'print_tables'\u001b[0m]\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'print_tables' 0x16c7cc650 (id: 9)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.489874\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask finished successfully    \u001b[0m [\u001b[0m\u001b[1m\u001b[34mTask 'print_tables'\u001b[0m]\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35m<FinalTaskState.CACHE_VALID: 2>\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m<Task 'print_tables' 0x16c7cc650 (id: 9)>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.490404\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCommitting stage              \u001b[0m [\u001b[0m\u001b[1m\u001b[34mCommit Stage\u001b[0m]\u001b[0m \u001b[36mstage\u001b[0m=\u001b[35m<Stage: t2_transformed_data>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.491557\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStage is cache valid          \u001b[0m [\u001b[0m\u001b[1m\u001b[34mDuckDBTableStore\u001b[0m]\u001b[0m \u001b[36mstage\u001b[0m=\u001b[35m<Stage: t2_transformed_data>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.494580\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask finished successfully    \u001b[0m [\u001b[0m\u001b[1m\u001b[34mCommit Stage\u001b[0m]\u001b[0m \u001b[36mstage\u001b[0m=\u001b[35m<Stage: t2_transformed_data>\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35m<FinalTaskState.COMPLETED: 1>\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.495990\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFlow visualization            \u001b[0m [\u001b[0m\u001b[1m\u001b[34mFlow\u001b[0m]\u001b[0m \u001b[36murl\u001b[0m=\u001b[35mhttps://kroki.io/graphviz/svg/eNqtkt1qwzAMhe_9FCa73SBL81dCdruHGMMosdOaqnFmO4wy-u5Laq9r1g1cmG8-LPkcSchcbjQMW_pMP4gZG3dpcTRWaGYfmYZ3JvthtFMeoRFYR5fRqCLGHlDURqHkFWk2rUKl6-guPp0knl64UIPQ7irSqd4uAjF98cZaAHe2jIOF6J52EvHLUJRd1-ZT0BWM5pzg0WtFjuSX1hNmNfSmU3ov-MnvYoLr5D8Mkp4HsWB23xUY74JHWS09BoWgTbA6-aGGnkO4Ovurf_OGwSb50kQ2MryBYqmdygK2W7E_BDuUVw7B0vVZOmjZW2ahQWFu-YMxfXiiSeW48kw9M8_cs_As561NXM-7d0w9M8_cs_AsPY_kEyR6MGw=\u001b[0m\n",
      "\u001b[2m2024-08-06 09:27:25.698848\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStopped IPCServer             \u001b[0m [\u001b[0m\u001b[1m\u001b[34mRunContextServer\u001b[0m]\u001b[0m \u001b[36maddress\u001b[0m=\u001b[35mtcp://127.0.0.1:64845\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1004pt\" height=\"257pt\" viewBox=\"0.00 0.00 1004.00 257.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 253)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-253 1000,-253 1000,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_t1_raw_input</title>\n",
       "<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"black\" points=\"450,-164.5 450,-241 606,-241 606,-164.5 450,-164.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-223.7\" font-family=\"Times,serif\" font-size=\"14.00\">t1_raw_input</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_t2_transformed_data</title>\n",
       "<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"black\" points=\"8,-8 8,-156.5 988,-156.5 988,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"498\" y=\"-139.2\" font-family=\"Times,serif\" font-size=\"14.00\">t2_transformed_data</text>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"528\" cy=\"-190.5\" rx=\"70.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-185.45\" font-family=\"Times,serif\" font-size=\"14.00\">read_input_data</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"95\" cy=\"-106\" rx=\"78.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"95\" y=\"-100.95\" font-family=\"Times,serif\" font-size=\"14.00\">task_transform_df</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>0-&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M459.12,-186.29C373.57,-181.72 232.81,-172.12 183,-156.5 163.47,-150.38 143.45,-139.54 127.45,-129.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"129.62,-126.8 119.32,-124.33 125.83,-132.69 129.62,-126.8\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"245\" cy=\"-106\" rx=\"52.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-100.95\" font-family=\"Times,serif\" font-size=\"14.00\">task_polars</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0-&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M457.73,-188.31C412.97,-185.34 354.65,-177.27 307,-156.5 293.19,-150.48 279.86,-140.57 269.13,-131.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"271.62,-128.73 261.88,-124.56 266.89,-133.89 271.62,-128.73\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"372\" cy=\"-106\" rx=\"55.96\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"372\" y=\"-100.95\" font-family=\"Times,serif\" font-size=\"14.00\">task_pandas</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0-&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M483.32,-176.32C468.18,-171.07 451.46,-164.39 437,-156.5 423.77,-149.28 410.32,-139.53 399.12,-130.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"401.41,-127.94 391.46,-124.3 396.97,-133.35 401.41,-127.94\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"528\" cy=\"-106\" rx=\"82.06\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-100.95\" font-family=\"Times,serif\" font-size=\"14.00\">task_transform_sql</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0-&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M528,-172C528,-161.5 528,-147.89 528,-135.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"531.5,-135.98 528,-125.98 524.5,-135.98 531.5,-135.98\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"672\" cy=\"-106\" rx=\"43.67\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"672\" y=\"-100.95\" font-family=\"Times,serif\" font-size=\"14.00\">task_ibis</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>0-&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M574.55,-176.66C589.34,-171.53 605.39,-164.84 619,-156.5 630.23,-149.62 641.13,-140.1 650.09,-131.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"652.53,-133.77 656.99,-124.16 647.51,-128.89 652.53,-133.77\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"807\" cy=\"-106\" rx=\"72.85\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"807\" y=\"-100.95\" font-family=\"Times,serif\" font-size=\"14.00\">task_sqlalchemy</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;7 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0-&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M594.82,-184.61C633.74,-180.22 683.21,-171.97 725,-156.5 742.78,-149.92 760.99,-139.38 775.72,-129.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"777.28,-132.89 783.6,-124.39 773.36,-127.09 777.28,-132.89\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"939\" cy=\"-106\" rx=\"41.12\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"939\" y=\"-100.95\" font-family=\"Times,serif\" font-size=\"14.00\">task_sql</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>0-&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M598.17,-188.67C688.28,-186.65 839.01,-179.78 889,-156.5 900.92,-150.95 911.65,-141.32 920.09,-132.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"922.66,-134.4 926.46,-124.5 917.32,-129.87 922.66,-134.4\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"528\" cy=\"-34\" rx=\"54.42\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-28.95\" font-family=\"Times,serif\" font-size=\"14.00\">print_tables</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>4-&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.17,-93.44C163.11,-91.55 173.34,-89.67 183,-88 282.4,-70.77 398.42,-53.54 467.41,-43.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"467.59,-47.1 476.99,-42.21 466.59,-40.17 467.59,-47.1\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>3-&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M284.97,-93.84C292.29,-91.85 299.87,-89.83 307,-88 363.54,-73.47 428.55,-58.03 473.35,-47.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"473.87,-51.06 482.81,-45.39 472.28,-44.24 473.87,-51.06\"/>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;9 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2-&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M403.57,-90.83C427.36,-80.16 460.2,-65.42 486.18,-53.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"487.41,-57.05 495.1,-49.76 484.54,-50.66 487.41,-57.05\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;9 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5-&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M528,-87.7C528,-80.41 528,-71.73 528,-63.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"531.5,-63.62 528,-53.62 524.5,-63.62 531.5,-63.62\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;9 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>6-&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M644.58,-91.67C622.87,-81.12 592.25,-66.23 567.84,-54.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"569.69,-51.37 559.17,-50.15 566.63,-57.67 569.69,-51.37\"/>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;9 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>7-&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M757.12,-92.49C707.58,-80.05 631.88,-61.06 581.2,-48.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"582.18,-44.98 571.62,-45.95 580.47,-51.77 582.18,-44.98\"/>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>8-&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M908.32,-93.59C901.99,-91.51 895.33,-89.53 889,-88 786.27,-63.21 664.13,-48.22 591.5,-40.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"592.08,-37.33 581.78,-39.81 591.38,-44.3 592.08,-37.33\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flow = get_pipeline()\n",
    "result = flow.run()\n",
    "result.visualize()\n",
    "assert result.successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Next: [vectorization08.ipynb](vectorization08.ipynb): window functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
