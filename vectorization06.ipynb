{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# introduction to the vectorizing principle\n",
    "\n",
    "## part 6: many ways to describe data transformations in python\n",
    "\n",
    "We have seen that both SQL databases and DataFrames are powerful tools to perform data transformations.\n",
    "In python, several libraries exist for this task with their own strengths and weaknesses:\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/) is the most popular library for working with DataFrames in python. However, it got extremely popular before its API design could be completed to an extent that it would avoid serious pitfalls in day-to-day code. Since it is that widely used and some problems are caused by core principles of the library, it cannot be expected that such problems just vanish by waiting long enough.\n",
    "- [Polars](https://www.pola.rs/) is a contender in the DataFrame space with fastly growing popularity. Its core implementation is in Rust and it has a modern architecture allowing for lazy expression building and optimized execution.\n",
    "- [Pydiverse.transform](https://github.com/pydiverse/pydiverse.transform/) was used in part 5 and can be used to work on DataFrames and SQL databases with the same syntax. While it is still an early stage open source project, the ambition is to provide the highest reliability of all tools targeting DataFrame and SQL execution backends for a defined set of most relevant data transformation operations.\n",
    "- [Ibis](https://ibis-project.org/) is a library that also tries to abstract the data transformation description from execution backends with a predominant focus on generating SQL expressions. While it already supports a wide range of operations and SQL dialects, there still seem to be some reliability issues which seem hard to fix given the current architecture.\n",
    "- [SQLAlchemy](https://www.sqlalchemy.org/) is the most widely used library for generating SQL expression with python code. However, its syntax has rough edges and is much less concise compared with the other tools.\n",
    "- SQL query strings can still be handwritten and form a powerful interface for describing data transformations in an ad-hoc fashion.\n",
    "\n",
    "It may be worth noting, that a pretty clean way of describing tabular data transformations was developed for the programming language R called [dplyr](https://dplyr.tidyverse.org/). It is the basis of the API design of various python libraries like pydiverse.transform, ibis, and tidypolars. So even if you do not intend to work with the programming language R, it is worth reading the [dplyr](https://dplyr.tidyverse.org/) documentation since it is a nice introduction to the field in general.\n",
    "\n",
    "#### the following code shows how to describe the join of two tables and adding a new column to the result works in different libraries:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import sqlalchemy as sa\n",
    "import ibis\n",
    "import pydiverse.transform as pdt\n",
    "from pydiverse.pipedag import Flow, Stage, Table, materialize\n",
    "from pydiverse.transform.core.verbs import (\n",
    "    left_join,\n",
    "    mutate,\n",
    "    select, alias,\n",
    ")\n",
    "from pydiverse.transform.eager import PandasTableImpl\n",
    "from pydiverse.transform.lazy import SQLTableImpl\n",
    "\n",
    "\n",
    "@materialize(input_type=pd.DataFrame, version=\"1.0.0\")\n",
    "def task_pandas(a: pd.DataFrame, b: pd.DataFrame):\n",
    "    return a.merge(b, on=\"pk\", how=\"left\").assign(x2=lambda df: df.x * df.x)\n",
    "\n",
    "\n",
    "@materialize(input_type=pl.DataFrame, version=\"1.0.0\")\n",
    "def task_polars(a: pl.DataFrame, b: pl.DataFrame):\n",
    "    x = pl.col(\"x\")\n",
    "    return a.join(b, on=\"pk\", how=\"left\").with_columns((x * x).alias(\"x2\"))\n",
    "\n",
    "\n",
    "@materialize(input_type=PandasTableImpl, version=\"1.0.0\")\n",
    "def task_transform_df(a: pdt.Table, b: pdt.Table):\n",
    "    return (\n",
    "        a >> left_join(b, pk_match(a, b)) >> mutate(x2=b.x * b.x)\n",
    "        >> alias(\"transform_df\")\n",
    "    )\n",
    "\n",
    "\n",
    "@materialize(input_type=SQLTableImpl, lazy=True)\n",
    "def task_transform_sql(a: pdt.Table, b: pdt.Table):\n",
    "    return (\n",
    "        a >> left_join(b, pk_match(a, b)) >> mutate(x2=b.x * b.x)\n",
    "        >> alias(\"transform_sql\")\n",
    "    )\n",
    "\n",
    "\n",
    "@materialize(input_type=ibis.api.Table, lazy=True)\n",
    "def task_ibis(a: ibis.api.Table, b: ibis.api.Table):\n",
    "    return a.left_join(b, pk_match(a, b)).mutate(x2=b.x * b.x)\n",
    "\n",
    "\n",
    "@materialize(input_type=sa.Table, lazy=True)\n",
    "def task_sqlalchemy(a: sa.Table, b: sa.Table):\n",
    "    return sa.select(\n",
    "        *a.c,\n",
    "        *[c for c in b.c if c.name not in a.c],\n",
    "        (b.c.x * b.c.x).label(\"x2\"),\n",
    "    ).select_from(a.outerjoin(b, pk_match_sa(a, b)))\n",
    "\n",
    "\n",
    "@materialize(input_type=sa.Table, lazy=True)\n",
    "def task_sql(a: sa.Table, b: sa.Table):\n",
    "    return sa.text(f\"\"\"\n",
    "        SELECT\n",
    "            a.*,\n",
    "            b.*,\n",
    "            b.x * b.x AS x2\n",
    "        FROM {a.original.schema}.{a.name} AS a\n",
    "        LEFT JOIN {b.original.schema}.{b.name} AS b\n",
    "        ON a.pk = b.pk\n",
    "    \"\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### define remaining tasks and helper functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "@pdt.verb\n",
    "def transmute(tbl, **kwargs):\n",
    "    return tbl >> select() >> mutate(**kwargs)\n",
    "\n",
    "\n",
    "@pdt.verb\n",
    "def trim_all_str(tbl):\n",
    "    for col in tbl:\n",
    "        if col._.dtype == \"str\":\n",
    "            tbl[col] = col.strip()\n",
    "    return tbl\n",
    "\n",
    "\n",
    "def pk(x: pdt.Table):\n",
    "    # This is just a placeholder.\n",
    "    # Ideally there would be a global function in pydiverse transform to\n",
    "    # get the primary key (and another one to get the table / col name)\n",
    "    return x.pk\n",
    "\n",
    "\n",
    "def pk_match(x: pdt.Table, y: pdt.Table):\n",
    "    return pk(x) == pk(y)\n",
    "\n",
    "\n",
    "def pk_match_sa(x: sa.Table, y: sa.Table):\n",
    "    # # we lost the primary_key already or duckdb cannot reflect it\n",
    "    # cond = sa.literal(True)\n",
    "    # for col in y.original.primary_key:\n",
    "    #     if col not in x.c:\n",
    "    #         cond &= x.c[col] == y.c[col]\n",
    "    return x.c.pk == y.c.pk  # hack: assume primary key is always on column pk\n",
    "\n",
    "def get_named_tables(tables: list[pdt.Table]) -> dict[str, pdt.Table]:\n",
    "    return {tbl._impl.name: tbl for tbl in tables}\n",
    "\n",
    "\n",
    "@materialize(version=\"1.0.0\")\n",
    "def read_input_data(src_dir=\"data/pipedag_example_data\"):\n",
    "    return [\n",
    "        Table(pd.read_csv(os.path.join(src_dir, file)), name=file.removesuffix(\".csv.gz\"))\n",
    "        for file in os.listdir(src_dir)\n",
    "        if file.endswith(\".csv.gz\")\n",
    "    ]\n",
    "\n",
    "\n",
    "@materialize(input_type=SQLTableImpl, lazy=True, nout=3)\n",
    "def clean(src_tbls: list[pdt.Table]):\n",
    "    out_tbls = [tbl >> trim_all_str() for tbl in src_tbls]\n",
    "    named_tbls = get_named_tables(out_tbls)\n",
    "    a = named_tbls[\"a\"]\n",
    "    b = named_tbls[\"b\"]\n",
    "    c = named_tbls[\"c\"]\n",
    "    return a, b, c\n",
    "\n",
    "\n",
    "@materialize(input_type=ibis.api.Table, version=\"1.0.0\")\n",
    "def check_x2_sum(tbls: list[ibis.api.Table]):\n",
    "    all_x2_sum = None\n",
    "    for tbl in tbls:\n",
    "        x2_sum = tbl.x2.sum().to_pandas()\n",
    "        if all_x2_sum is None:\n",
    "            all_x2_sum = x2_sum\n",
    "        else:\n",
    "            assert x2_sum == all_x2_sum\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### define pipeline:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_pipeline():\n",
    "    tasks = [task_pandas, task_polars, task_transform_df, task_transform_sql,\n",
    "             task_ibis, task_sqlalchemy, task_sql]\n",
    "    with Flow(\"flow\") as flow:\n",
    "        with Stage(\"x1_raw_input\"):\n",
    "            raw_tbls = read_input_data()\n",
    "\n",
    "        with Stage(\"x2_clean_input\"):\n",
    "            a, b, c = clean(raw_tbls)\n",
    "\n",
    "        with Stage(\"x3_transformed_data\"):\n",
    "            out_tbls = [task(a, b) for task in tasks]\n",
    "\n",
    "        with Stage(\"x4_check\"):\n",
    "            check_x2_sum(out_tbls)\n",
    "\n",
    "    return flow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### setup logging:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import logging\n",
    "from pydiverse.pipedag.util.structlog import setup_logging\n",
    "setup_logging(log_level=logging.INFO)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### run pipeline:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m2023-08-08 13:29:30.131052\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mInitialized SQL Table Store   \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \u001B[36mengine_url\u001B[0m=\u001B[35mduckdb:////tmp/pipedag/vectorization/db.duckdb\u001B[0m \u001B[36mschema_prefix\u001B[0m=\u001B[35m\u001B[0m \u001B[36mschema_suffix\u001B[0m=\u001B[35m\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.139182\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mStarting IPCServer            \u001B[0m [\u001B[34m\u001B[1mRunContextServer\u001B[0m] \u001B[36maddress\u001B[0m=\u001B[35mtcp://127.0.0.1:34283\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.142004\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mInitialized SQL Table Store   \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \u001B[36mengine_url\u001B[0m=\u001B[35mduckdb:////tmp/pipedag/vectorization/db.duckdb\u001B[0m \u001B[36mschema_prefix\u001B[0m=\u001B[35m\u001B[0m \u001B[36mschema_suffix\u001B[0m=\u001B[35m\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.189611\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE SCHEMA IF NOT EXISTS pipedag_metadata\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.220354\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE SCHEMA IF NOT EXISTS x1_raw_input\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.221408\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP SCHEMA IF EXISTS x1_raw_input__even CASCADE\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.228556\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE SCHEMA x1_raw_input__even\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.262467\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x1_raw_input__even.a AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x1_raw_input.a\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.276766\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x1_raw_input__even.b AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x1_raw_input.b\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.288390\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x1_raw_input__even.c AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x1_raw_input.c\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.300141\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFound task in cache. Using cached result.\u001B[0m [\u001B[34m\u001B[1mTask 'read_input_data'\u001B[0m] \u001B[36mtask\u001B[0m=\u001B[35m<Task 'read_input_data' 0x7fc249a01600 (id: 0)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.303837\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mTask 'read_input_data'\u001B[0m] \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.CACHE_VALID: 2>\u001B[0m \u001B[36mtask\u001B[0m=\u001B[35m<Task 'read_input_data' 0x7fc249a01600 (id: 0)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.305985\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mCommitting stage              \u001B[0m [\u001B[34m\u001B[1mCommit Stage\u001B[0m] \u001B[36mstage\u001B[0m=\u001B[35m<Stage: x1_raw_input>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.309970\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mStage is cache valid          \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \u001B[36mstage\u001B[0m=\u001B[35m<Stage: x1_raw_input>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.319489\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mCommit Stage\u001B[0m] \u001B[36mstage\u001B[0m=\u001B[35m<Stage: x1_raw_input>\u001B[0m \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.COMPLETED: 1>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.324810\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE SCHEMA IF NOT EXISTS x2_clean_input\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.325692\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP SCHEMA IF EXISTS x2_clean_input__even CASCADE\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.327405\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE SCHEMA x2_clean_input__even\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.339241\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'pydiverse.transform.lazy.sql_table.SQLTableImpl'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'a' (x1_raw_input)>\u001B[0m\n",
      "/home/martin/progs/miniconda3/envs/vectorization/lib/python3.10/site-packages/duckdb_engine/__init__.py:162: DuckDBEngineWarning: duckdb-engine doesn't yet support reflection on indices\n",
      "  warnings.warn(\n",
      "\u001B[2m2023-08-08 13:29:30.439494\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'pydiverse.transform.lazy.sql_table.SQLTableImpl'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'b' (x1_raw_input)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.513660\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'pydiverse.transform.lazy.sql_table.SQLTableImpl'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'c' (x1_raw_input)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.605978\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x2_clean_input__even.a AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x2_clean_input.a\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.617348\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mLazy cache of table 'a' found \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "\u001B[2m2023-08-08 13:29:30.629291\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x2_clean_input__even.b AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x2_clean_input.b\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.634508\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mLazy cache of table 'b' found \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "\u001B[2m2023-08-08 13:29:30.645412\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x2_clean_input__even.c AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x2_clean_input.c\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.650924\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mLazy cache of table 'c' found \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "\u001B[2m2023-08-08 13:29:30.662391\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mTask 'clean'\u001B[0m] \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.CACHE_VALID: 2>\u001B[0m \u001B[36mtask\u001B[0m=\u001B[35m<Task 'clean' 0x7fc249a00640 (id: 2)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.664042\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mCommitting stage              \u001B[0m [\u001B[34m\u001B[1mCommit Stage\u001B[0m] \u001B[36mstage\u001B[0m=\u001B[35m<Stage: x2_clean_input>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.667128\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mStage is cache valid          \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \u001B[36mstage\u001B[0m=\u001B[35m<Stage: x2_clean_input>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.676370\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mCommit Stage\u001B[0m] \u001B[36mstage\u001B[0m=\u001B[35m<Stage: x2_clean_input>\u001B[0m \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.COMPLETED: 1>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.681674\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE SCHEMA IF NOT EXISTS x3_transformed_data\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.682908\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP SCHEMA IF EXISTS x3_transformed_data__odd CASCADE\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.684962\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE SCHEMA x3_transformed_data__odd\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.709075\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data__odd.task_pandas_tunnatry47i4dkjizy5o_0000 AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data.task_pandas_tunnatry47i4dkjizy5o_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.720096\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFound task in cache. Using cached result.\u001B[0m [\u001B[34m\u001B[1mTask 'task_pandas'\u001B[0m] \u001B[36mtask\u001B[0m=\u001B[35m<Task 'task_pandas' 0x7fc249a013c0 (id: 4)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.723278\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mTask 'task_pandas'\u001B[0m] \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.CACHE_VALID: 2>\u001B[0m \u001B[36mtask\u001B[0m=\u001B[35m<Task 'task_pandas' 0x7fc249a013c0 (id: 4)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.736981\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data__odd.task_polars_tyzncvmv46gyh4pbhjf6_0000 AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data.task_polars_tyzncvmv46gyh4pbhjf6_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.746845\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFound task in cache. Using cached result.\u001B[0m [\u001B[34m\u001B[1mTask 'task_polars'\u001B[0m] \u001B[36mtask\u001B[0m=\u001B[35m<Task 'task_polars' 0x7fc249a01360 (id: 5)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.749682\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mTask 'task_polars'\u001B[0m] \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.CACHE_VALID: 2>\u001B[0m \u001B[36mtask\u001B[0m=\u001B[35m<Task 'task_polars' 0x7fc249a01360 (id: 5)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.764838\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data__odd.a AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data.a\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.773484\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFound task in cache. Using cached result.\u001B[0m [\u001B[34m\u001B[1mTask 'task_transform_df'\u001B[0m] \u001B[36mtask\u001B[0m=\u001B[35m<Task 'task_transform_df' 0x7fc249a013f0 (id: 6)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.775590\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mTask 'task_transform_df'\u001B[0m] \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.CACHE_VALID: 2>\u001B[0m \u001B[36mtask\u001B[0m=\u001B[35m<Task 'task_transform_df' 0x7fc249a013f0 (id: 6)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.782753\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'pydiverse.transform.lazy.sql_table.SQLTableImpl'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'a' (x2_clean_input)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.857972\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'pydiverse.transform.lazy.sql_table.SQLTableImpl'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'b' (x2_clean_input)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.939790\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data__odd.transform_sql AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data.transform_sql\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.951041\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mLazy cache of table 'transform_sql' found\u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "\u001B[2m2023-08-08 13:29:30.960374\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mTask 'task_transform_sql'\u001B[0m] \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.CACHE_VALID: 2>\u001B[0m \u001B[36mtask\u001B[0m=\u001B[35m<Task 'task_transform_sql' 0x7fc249a03a90 (id: 7)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:30.968639\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'ibis.expr.types.relations.Table'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'a' (x2_clean_input)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.078285\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'ibis.expr.types.relations.Table'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'b' (x2_clean_input)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.304637\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data__odd.task_ibis_zbu5jvlwrj3jlqkuiohv_0000 AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data.task_ibis_zbu5jvlwrj3jlqkuiohv_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.315892\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mLazy cache of table 'task_ibis_zbu5jvlwrj3jlqkuiohv_0000' found\u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "\u001B[2m2023-08-08 13:29:31.326759\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mTask 'task_ibis'\u001B[0m] \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.CACHE_VALID: 2>\u001B[0m \u001B[36mtask\u001B[0m=\u001B[35m<Task 'task_ibis' 0x7fc249a02530 (id: 8)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.335674\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'sqlalchemy.sql.schema.Table'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'a' (x2_clean_input)>\u001B[0m\n",
      "/home/martin/progs/miniconda3/envs/vectorization/lib/python3.10/site-packages/duckdb_engine/__init__.py:162: DuckDBEngineWarning: duckdb-engine doesn't yet support reflection on indices\n",
      "  warnings.warn(\n",
      "\u001B[2m2023-08-08 13:29:31.414203\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'sqlalchemy.sql.schema.Table'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'b' (x2_clean_input)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.502451\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data__odd.task_sqlalchemy_qvazvchzg6wcriolrns3_0000 AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data.task_sqlalchemy_qvazvchzg6wcriolrns3_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.514063\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mLazy cache of table 'task_sqlalchemy_qvazvchzg6wcriolrns3_0000' found\u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "\u001B[2m2023-08-08 13:29:31.524309\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mTask 'task_sqlalchemy'\u001B[0m] \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.CACHE_VALID: 2>\u001B[0m \u001B[36mtask\u001B[0m=\u001B[35m<Task 'task_sqlalchemy' 0x7fc249a02ce0 (id: 9)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.534005\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'sqlalchemy.sql.schema.Table'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'a' (x2_clean_input)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.615405\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'sqlalchemy.sql.schema.Table'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'b' (x2_clean_input)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.699065\u001B[0m [\u001B[33m\u001B[1mwarning  \u001B[0m] \u001B[1mCache miss                    \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mNo result found for lazy table cache key\u001B[0m \u001B[36mstage\u001B[0m=\u001B[35mx3_transformed_data\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35mtask_sql_dhn42qjk3stm2zrlwe5i_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.716868\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE TABLE x3_transformed_data__odd.task_sql_dhn42qjk3stm2zrlwe5i_0000 AS\n",
      "\n",
      "    \u001B[35m        SELECT\n",
      "    \u001B[35m            a.*,\n",
      "    \u001B[35m            b.*,\n",
      "    \u001B[35m            b.x * b.x AS x2\n",
      "    \u001B[35m        FROM x2_clean_input.a AS a\n",
      "    \u001B[35m        LEFT JOIN x2_clean_input.b AS b\n",
      "    \u001B[35m        ON a.pk = b.pk\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.719539\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE TABLE x3_transformed_data__odd.task_pandas_tunnatry47i4dkjizy5o_0000__copy AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data.task_pandas_tunnatry47i4dkjizy5o_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.727317\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE TABLE x3_transformed_data__odd.transform_sql__copy AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data.transform_sql\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.730580\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE TABLE x3_transformed_data__odd.task_ibis_zbu5jvlwrj3jlqkuiohv_0000__copy AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data.task_ibis_zbu5jvlwrj3jlqkuiohv_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.731152\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE TABLE x3_transformed_data__odd.task_polars_tyzncvmv46gyh4pbhjf6_0000__copy AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data.task_polars_tyzncvmv46gyh4pbhjf6_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.732323\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE TABLE x3_transformed_data__odd.task_sqlalchemy_qvazvchzg6wcriolrns3_0000__copy AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data.task_sqlalchemy_qvazvchzg6wcriolrns3_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.733322\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE TABLE x3_transformed_data__odd.a__copy AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data.a\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.745139\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mTask 'task_sql'\u001B[0m] \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.COMPLETED: 1>\u001B[0m \u001B[36mtask\u001B[0m=\u001B[35m<Task 'task_sql' 0x7fc249a02260 (id: 10)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.747004\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mCommitting stage              \u001B[0m [\u001B[34m\u001B[1mCommit Stage\u001B[0m] \u001B[36mstage\u001B[0m=\u001B[35m<Stage: x3_transformed_data>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.749348\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data__odd.task_pandas_tunnatry47i4dkjizy5o_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.749541\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data__odd.task_polars_tyzncvmv46gyh4pbhjf6_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.749999\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data__odd.a\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.750320\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data__odd.task_sqlalchemy_qvazvchzg6wcriolrns3_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.750617\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data__odd.task_ibis_zbu5jvlwrj3jlqkuiohv_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.750681\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data__odd.transform_sql\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.754457\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mALTER TABLE x3_transformed_data__odd.task_pandas_tunnatry47i4dkjizy5o_0000__copy RENAME TO task_pandas_tunnatry47i4dkjizy5o_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.756022\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mALTER TABLE x3_transformed_data__odd.a__copy RENAME TO a\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.756318\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mALTER TABLE x3_transformed_data__odd.task_sqlalchemy_qvazvchzg6wcriolrns3_0000__copy RENAME TO task_sqlalchemy_qvazvchzg6wcriolrns3_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.757556\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mALTER TABLE x3_transformed_data__odd.task_polars_tyzncvmv46gyh4pbhjf6_0000__copy RENAME TO task_polars_tyzncvmv46gyh4pbhjf6_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.758944\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mALTER TABLE x3_transformed_data__odd.task_ibis_zbu5jvlwrj3jlqkuiohv_0000__copy RENAME TO task_ibis_zbu5jvlwrj3jlqkuiohv_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.760348\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mALTER TABLE x3_transformed_data__odd.transform_sql__copy RENAME TO transform_sql\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.778085\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data.task_ibis_zbu5jvlwrj3jlqkuiohv_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.779032\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data.task_sqlalchemy_qvazvchzg6wcriolrns3_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.779982\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data.task_polars_tyzncvmv46gyh4pbhjf6_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.780767\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data.transform_sql\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.781535\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data.a\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.782656\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data.task_pandas_tunnatry47i4dkjizy5o_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.783568\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP VIEW x3_transformed_data.task_sql_dhn42qjk3stm2zrlwe5i_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.794155\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data.a AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data__odd.a\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.797091\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data.task_sqlalchemy_qvazvchzg6wcriolrns3_0000 AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data__odd.task_sqlalchemy_qvazvchzg6wcriolrns3_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.799566\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data.task_polars_tyzncvmv46gyh4pbhjf6_0000 AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data__odd.task_polars_tyzncvmv46gyh4pbhjf6_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.801934\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data.task_ibis_zbu5jvlwrj3jlqkuiohv_0000 AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data__odd.task_ibis_zbu5jvlwrj3jlqkuiohv_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.804344\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data.transform_sql AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data__odd.transform_sql\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.806360\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data.task_pandas_tunnatry47i4dkjizy5o_0000 AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data__odd.task_pandas_tunnatry47i4dkjizy5o_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.808349\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE VIEW x3_transformed_data.task_sql_dhn42qjk3stm2zrlwe5i_0000 AS\n",
      "    \u001B[35mSELECT * \n",
      "    \u001B[35mFROM x3_transformed_data__odd.task_sql_dhn42qjk3stm2zrlwe5i_0000\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.818945\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mCommit Stage\u001B[0m] \u001B[36mstage\u001B[0m=\u001B[35m<Stage: x3_transformed_data>\u001B[0m \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.COMPLETED: 1>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.823355\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE SCHEMA IF NOT EXISTS x4_check\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.824376\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mDROP SCHEMA IF EXISTS x4_check__odd CASCADE\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.826228\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mExecuting sql                 \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \n",
      "    [\u001B[36mquery\u001B[0m]\n",
      "    \u001B[35mCREATE SCHEMA x4_check__odd\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.834677\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve task from cache\u001B[0m [\u001B[34m\u001B[1mTask 'check_x2_sum'\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCouldn't retrieve task from cache: <Task 'check_x2_sum' 0x7fc1d0c81ae0 (id: 12)>\u001B[0m \u001B[36mtask\u001B[0m=\u001B[35m<Task 'check_x2_sum' 0x7fc1d0c81ae0 (id: 12)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.836271\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'ibis.expr.types.relations.Table'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'task_pandas_tunnatry47i4dkjizy5o_0000' (x3_transformed_data)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.921935\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'ibis.expr.types.relations.Table'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'task_polars_tyzncvmv46gyh4pbhjf6_0000' (x3_transformed_data)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:31.996368\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'ibis.expr.types.relations.Table'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'a' (x3_transformed_data)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:32.068412\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'ibis.expr.types.relations.Table'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'transform_sql' (x3_transformed_data)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:32.142090\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'ibis.expr.types.relations.Table'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'task_ibis_zbu5jvlwrj3jlqkuiohv_0000' (x3_transformed_data)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:32.212694\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFailed to retrieve table from local table cache\u001B[0m [\u001B[34m\u001B[1mParquetTableCache\u001B[0m] \u001B[36mcause\u001B[0m=\u001B[35mCan't retrieve Table as type <class 'ibis.expr.types.relations.Table'>\u001B[0m \u001B[36mtable\u001B[0m=\u001B[35m<Table 'task_sqlalchemy_qvazvchzg6wcriolrns3_0000' (x3_transformed_data)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:32.924191\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mTask 'check_x2_sum'\u001B[0m] \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.COMPLETED: 1>\u001B[0m \u001B[36mtask\u001B[0m=\u001B[35m<Task 'check_x2_sum' 0x7fc1d0c81ae0 (id: 12)>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:32.926060\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mCommitting stage              \u001B[0m [\u001B[34m\u001B[1mCommit Stage\u001B[0m] \u001B[36mstage\u001B[0m=\u001B[35m<Stage: x4_check>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:32.930215\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mStage is cache valid          \u001B[0m [\u001B[34m\u001B[1mDuckDBTableStore\u001B[0m] \u001B[36mstage\u001B[0m=\u001B[35m<Stage: x4_check>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:32.939220\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mTask finished successfully    \u001B[0m [\u001B[34m\u001B[1mCommit Stage\u001B[0m] \u001B[36mstage\u001B[0m=\u001B[35m<Stage: x4_check>\u001B[0m \u001B[36mstate\u001B[0m=\u001B[35m<FinalTaskState.COMPLETED: 1>\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:33.141728\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mStopped IPCServer             \u001B[0m [\u001B[34m\u001B[1mRunContextServer\u001B[0m] \u001B[36maddress\u001B[0m=\u001B[35mtcp://127.0.0.1:34283\u001B[0m\n",
      "\u001B[2m2023-08-08 13:29:33.157527\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mFlow visualization            \u001B[0m [\u001B[34m\u001B[1mFlow\u001B[0m] \u001B[36murl\u001B[0m=\u001B[35mhttps://kroki.io/graphviz/svg/eNqtU91ugjAYve9TNOzWJcAUIcTd7iGWpfnojxI_wbUlm1l89wmUZWKjLK4359DmHE6_nIpyrWG_oS_0i5im6D84NsZKzT4jpuGDldW-safzYs1rrPUqeAi7FYdBTvqtAoFvc6Lqyp5tIBQSV799cmLsAeXK1FiKnIT0VZWIg7FMleJJMKO9UEsQvYwJsDCjvTZoJVIEbzk5Ek_smHGUUP1D8DOnUfT4avRONzXwE7MaKqNqvZOiu-pdqS_tRtHnV6NbMFu2h0qA8VxgMUFbI2ifNrutNe8IyDdyd_Doo1FdQEiVFRcGHmVy-88_M2NCeRyWf3Hwh0hvW5RFaaa2Zs5Oc-Lbu6riPEb9iOKrc-4k7TMzzc4fNqSPzzRu38gJ5w4XDhOHS4epw8xhFLYNbUnc1s2RZCDLgaQDyQYShQM7km_xpJM2\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.SVG object>",
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1033pt\" height=\"363pt\" viewBox=\"0.00 0.00 1033.00 363.08\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 359.08)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-359.08 1029,-359.08 1029,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_x1_raw_input</title>\n<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"black\" points=\"455,-268.31 455,-347.08 617,-347.08 617,-268.31 455,-268.31\"/>\n<text text-anchor=\"middle\" x=\"536\" y=\"-329.78\" font-family=\"Times,serif\" font-size=\"14.00\">x1_raw_input</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_x2_clean_input</title>\n<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"black\" points=\"487,-181.54 487,-260.31 586,-260.31 586,-181.54 487,-181.54\"/>\n<text text-anchor=\"middle\" x=\"536.5\" y=\"-243.01\" font-family=\"Times,serif\" font-size=\"14.00\">x2_clean_input</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_x3_transformed_data</title>\n<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"black\" points=\"8,-94.77 8,-173.54 1017,-173.54 1017,-94.77 8,-94.77\"/>\n<text text-anchor=\"middle\" x=\"512.5\" y=\"-156.24\" font-family=\"Times,serif\" font-size=\"14.00\">x3_transformed_data</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_x4_check</title>\n<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"black\" points=\"459,-8 459,-86.77 613,-86.77 613,-8 459,-8\"/>\n<text text-anchor=\"middle\" x=\"536\" y=\"-69.47\" font-family=\"Times,serif\" font-size=\"14.00\">x4_check</text>\n</g>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"536\" cy=\"-294.69\" rx=\"72.83\" ry=\"18.38\"/>\n<text text-anchor=\"middle\" x=\"536\" y=\"-290.39\" font-family=\"Times,serif\" font-size=\"14.00\">read_input_data</text>\n</g>\n<!-- 2 -->\n<g id=\"node2\" class=\"node\">\n<title>2</title>\n<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"536\" cy=\"-207.92\" rx=\"31.47\" ry=\"18.38\"/>\n<text text-anchor=\"middle\" x=\"536\" y=\"-203.62\" font-family=\"Times,serif\" font-size=\"14.00\">clean</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0-&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M536,-276.13C536,-264.95 536,-250.22 536,-237.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"539.5,-237.76 536,-227.76 532.5,-237.76 539.5,-237.76\"/>\n</g>\n<!-- 4 -->\n<g id=\"node3\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"951\" cy=\"-121.15\" rx=\"57.98\" ry=\"18.38\"/>\n<text text-anchor=\"middle\" x=\"951\" y=\"-116.85\" font-family=\"Times,serif\" font-size=\"14.00\">task_pandas</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge2\" class=\"edge\">\n<title>2-&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M567.75,-206.11C642.35,-203.83 826.82,-196.04 884,-173.54 899.59,-167.4 914.61,-156.51 926.46,-146.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"928.39,-149.4 933.5,-140.11 923.72,-144.19 928.39,-149.4\"/>\n</g>\n<!-- 5 -->\n<g id=\"node4\" class=\"node\">\n<title>5</title>\n<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"820\" cy=\"-121.15\" rx=\"54.8\" ry=\"18.38\"/>\n<text text-anchor=\"middle\" x=\"820\" y=\"-116.85\" font-family=\"Times,serif\" font-size=\"14.00\">task_polars</text>\n</g>\n<!-- 2&#45;&gt;5 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2-&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M567.66,-207.2C611.73,-206.49 693.21,-201.1 756,-173.54 770.66,-167.11 784.78,-156.42 796.01,-146.46\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"798.04,-149.42 803,-140.06 793.28,-144.29 798.04,-149.42\"/>\n</g>\n<!-- 9 -->\n<g id=\"node5\" class=\"node\">\n<title>9</title>\n<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"672\" cy=\"-121.15\" rx=\"74.95\" ry=\"18.38\"/>\n<text text-anchor=\"middle\" x=\"672\" y=\"-116.85\" font-family=\"Times,serif\" font-size=\"14.00\">task_sqlalchemy</text>\n</g>\n<!-- 2&#45;&gt;9 -->\n<g id=\"edge7\" class=\"edge\">\n<title>2-&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M556.95,-193.86C578.09,-180.69 611.14,-160.09 636.4,-144.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"638.02,-146.83 644.66,-138.57 634.32,-140.89 638.02,-146.83\"/>\n</g>\n<!-- 10 -->\n<g id=\"node6\" class=\"node\">\n<title>10</title>\n<ellipse fill=\"#adef9b\" stroke=\"black\" cx=\"536\" cy=\"-121.15\" rx=\"42.6\" ry=\"18.38\"/>\n<text text-anchor=\"middle\" x=\"536\" y=\"-116.85\" font-family=\"Times,serif\" font-size=\"14.00\">task_sql</text>\n</g>\n<!-- 2&#45;&gt;10 -->\n<g id=\"edge8\" class=\"edge\">\n<title>2-&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M536,-189.36C536,-178.18 536,-163.45 536,-150.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"539.5,-150.99 536,-140.99 532.5,-150.99 539.5,-150.99\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"394\" cy=\"-121.15\" rx=\"81.85\" ry=\"18.38\"/>\n<text text-anchor=\"middle\" x=\"394\" y=\"-116.85\" font-family=\"Times,serif\" font-size=\"14.00\">task_transform_df</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2-&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M514.43,-194.05C492.39,-180.89 457.73,-160.2 431.24,-144.38\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"433.27,-140.92 422.89,-138.8 429.68,-146.93 433.27,-140.92\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"209\" cy=\"-121.15\" rx=\"85.03\" ry=\"18.38\"/>\n<text text-anchor=\"middle\" x=\"209\" y=\"-116.85\" font-family=\"Times,serif\" font-size=\"14.00\">task_transform_sql</text>\n</g>\n<!-- 2&#45;&gt;7 -->\n<g id=\"edge5\" class=\"edge\">\n<title>2-&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M504.28,-205.95C458.67,-203.76 372.4,-196.64 303,-173.54 282.15,-166.6 260.53,-155.13 243.29,-144.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"245.54,-141.44 235.19,-139.18 241.87,-147.4 245.54,-141.44\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<ellipse fill=\"#e8ffc6\" stroke=\"black\" cx=\"61\" cy=\"-121.15\" rx=\"45.25\" ry=\"18.38\"/>\n<text text-anchor=\"middle\" x=\"61\" y=\"-116.85\" font-family=\"Times,serif\" font-size=\"14.00\">task_ibis</text>\n</g>\n<!-- 2&#45;&gt;8 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2-&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M504.18,-207.12C418.47,-207.23 184.55,-204.58 115,-173.54 101.89,-167.69 90,-157.26 80.74,-147.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"82.83,-145.4 73.61,-140.19 77.57,-150.02 82.83,-145.4\"/>\n</g>\n<!-- 12 -->\n<g id=\"node10\" class=\"node\">\n<title>12</title>\n<ellipse fill=\"#adef9b\" stroke=\"black\" cx=\"536\" cy=\"-34.38\" rx=\"69.12\" ry=\"18.38\"/>\n<text text-anchor=\"middle\" x=\"536\" y=\"-30.08\" font-family=\"Times,serif\" font-size=\"14.00\">check_x2_sum</text>\n</g>\n<!-- 4&#45;&gt;12 -->\n<g id=\"edge9\" class=\"edge\">\n<title>4-&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M916.99,-105.81C906.55,-101.81 894.92,-97.74 884,-94.77 790.76,-69.41 680.38,-52.76 609.33,-43.71\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"610.07,-40.15 599.71,-42.38 609.19,-47.1 610.07,-40.15\"/>\n</g>\n<!-- 5&#45;&gt;12 -->\n<g id=\"edge10\" class=\"edge\">\n<title>5-&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M786.72,-106.12C776.91,-102.21 766.1,-98.12 756,-94.77 702.93,-77.15 641.4,-60.88 596.92,-49.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"597.83,-46.22 587.29,-47.22 596.16,-53.01 597.83,-46.22\"/>\n</g>\n<!-- 9&#45;&gt;12 -->\n<g id=\"edge14\" class=\"edge\">\n<title>9-&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M645.45,-103.61C624.26,-90.4 594.37,-71.77 571.18,-57.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"573.35,-53.92 563.02,-51.6 569.65,-59.86 573.35,-53.92\"/>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge15\" class=\"edge\">\n<title>10-&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M536,-102.59C536,-91.41 536,-76.68 536,-63.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"539.5,-64.22 536,-54.22 532.5,-64.22 539.5,-64.22\"/>\n</g>\n<!-- 6&#45;&gt;12 -->\n<g id=\"edge11\" class=\"edge\">\n<title>6-&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M422.05,-103.41C444.32,-90.12 475.6,-71.44 499.76,-57.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"501.17,-59.65 507.97,-51.52 497.59,-53.64 501.17,-59.65\"/>\n</g>\n<!-- 7&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>7-&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M260.19,-106.19C274.07,-102.44 289.1,-98.42 303,-94.77 361.81,-79.33 429.13,-62.24 476.23,-50.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"477.01,-53.53 485.86,-47.69 475.3,-46.74 477.01,-53.53\"/>\n</g>\n<!-- 8&#45;&gt;12 -->\n<g id=\"edge13\" class=\"edge\">\n<title>8-&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M87.29,-105.87C95.91,-101.71 105.67,-97.55 115,-94.77 231.22,-60.12 371.67,-45.48 457.38,-39.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"457.59,-42.87 467.33,-38.7 457.11,-35.89 457.59,-42.87\"/>\n</g>\n</g>\n</svg>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flow = get_pipeline()\n",
    "result = flow.run()\n",
    "result.visualize()\n",
    "assert result.successful"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
